schema: '2.0'
stages:
  preprocess_dataset:
    cmd: PYTHONPATH=. python3 experiments/scripts/preprocess_dataset.py
    deps:
    - path: experiments/scripts/preprocess_dataset.py
      md5: e318decabafbc20513b3b0184505ffc3
      size: 540
    params:
      params.yaml:
        preprocess_dataset.smiles2graph:
          cls: src.smiles.Smiles2GraphOGBConverter
          args: {}
    outs:
    - path: data/dataset/
      md5: b73ffb2c0b23563450be11ad150e6806.dir
      size: 20116395933
      nfiles: 7
  train_supervised@diffpool:
    cmd: PYTHONPATH=. python3 experiments/scripts/train_supervised.py --model-name
      diffpool --config-path experiments/configs/diffpool.yaml --checkpoint-dir data/supervised/diffpool/checkpoints
      --save-test-dir data/supervised/diffpool/submssion --metrics-path data/metrics/supervised/diffpool.json
      --log-dir data/supervised/diffpool/logs
    deps:
    - path: data/dataset/
      md5: b73ffb2c0b23563450be11ad150e6806.dir
      size: 20116395933
      nfiles: 7
    params:
      experiments/configs/diffpool.yaml:
        args:
          graph_pooling: sum
          drop_ratio: 0
          num_layers: 5
          emb_dim: 600
        data_loader_args:
          batch_size: 256
        dataset: ogb.lsc.DglPCQM4MDataset
        learning_args:
          epochs: 1
        reg: torch.nn.L1Loss
        step_lr:
          step_size: 300
          gamma: 0.25
    outs:
    - path: data/metrics/supervised/diffpool.json
      md5: 4a0fff2b6ef9d11c0379d34e5c40c262
      size: 150
    - path: data/supervised/diffpool/
      md5: 1b0b549409741e30d256b001650e194f.dir
      size: 94434306
      nfiles: 3
  train_gae:
    cmd: PYTHONPATH=. python3 experiments/scripts/train_unsupervised.py gae
    deps:
    - path: data/dataset/
      md5: 4a50c6545464f8a04bfcc49d2a660d25.dir
      size: 8538784731
      nfiles: 6
    - path: experiments/scripts/train_unsupervised.py
      md5: 718552683bf3db540d4b4318d3b5608b
      size: 7230
    - path: src/models/gae.py
      md5: 559dde28cad802f222cb30561e8d647a
      size: 6663
    params:
      params.yaml:
        gae:
          num_layers: 3
          emb_dim: 600
          batch_size: 256
          epochs: 15
    outs:
    - path: data/checkpoints/gae/
      md5: 458316bb1c3207d6b8e9e50d80e9c0e4.dir
      size: 16092025
      nfiles: 1
    - path: data/logs/gae/
      md5: 403ab99d1480ae99863b9d3a42ef7746.dir
      size: 2215
      nfiles: 1
    - path: data/submissions/gae/
      md5: b3a80c7cf68709b318deca7dde69fda5.dir
      size: 1279404
      nfiles: 1
